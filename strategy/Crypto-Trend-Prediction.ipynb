{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "embedded-mortality",
   "metadata": {},
   "source": [
    "# Crypto Trend Prediction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "abandoned-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Data sampling library \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model library\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Regression library\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Evaluation library\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Indicator\n",
    "from stockstats import StockDataFrame\n",
    "\n",
    "# Other\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "protected-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://www.kaggle.com/tencars/392-crypto-currency-pairs-at-minute-resolution/version/948?select=etheur.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-travel",
   "metadata": {},
   "source": [
    "# Function for data manipulation\n",
    "\n",
    "The next block contains the following functions:\n",
    "* ```make_df``` that import the csv file and transform the timestamp to datetime\n",
    "* ```meanfill``` that fill the minutes that are missing in the data\n",
    "* ```trim``` that split the df into timeframe\n",
    "* ```trend``` that find the trend in the current timeframe (1 crescend 0 decrescent)\n",
    "* ```make_label``` that find the inversion trend point into the timeframe\n",
    "* ```ema``` that calculate the Exponential Moving Average for the Close values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "mineral-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data and removing some row\n",
    "\n",
    "def make_df(csv_name):\n",
    "    \n",
    "    df = pd.read_csv(csv_name)\n",
    "    df = df.iloc[10: , :]\n",
    "      \n",
    "    # timestamp to datetime for finding missing minutes\n",
    "    df['time'] = pd.to_datetime(df.time, unit='ms')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# filling missing data with mean from last and next known value\n",
    "\n",
    "def meanfill(df):\n",
    "    backfill = df.set_index('time').asfreq(freq='1Min', method='backfill')\n",
    "    pad = df.set_index('time').asfreq(freq='1Min', method='pad')\n",
    "    \n",
    "    return pd.concat([backfill, pad]).groupby(level=0).mean()\n",
    "\n",
    "# grouping dataframe for selected timeframe\n",
    "\n",
    "def trim(dataframe, n):\n",
    "    df_list = []\n",
    "    i = 0\n",
    "    while i+n <= len(dataframe):\n",
    "        df_list.append(dataframe.iloc[i:n+i])\n",
    "        i += n\n",
    "    return df_list\n",
    "\n",
    "# selecting trend and removing timeframe with all missing values\n",
    "\n",
    "def trend(dataframe, timeframe):\n",
    "    \n",
    "    df_list = trim(dataframe, timeframe)\n",
    "    for i in range(len(df_list)):\n",
    "        index_min = df_list[i]['low'].idxmin()\n",
    "        index_max = df_list[i]['high'].idxmax()\n",
    "        \n",
    "        if df_list[i]['open'].mean() == df_list[i]['open'].iloc[0]:\n",
    "            df_list[i].loc[:,'trend'] = np.nan\n",
    "        elif index_min < index_max:\n",
    "            df_list[i].loc[:,'trend'] = 1\n",
    "    return df_list\n",
    "\n",
    "# Buy signal: 1\n",
    "# Sell signal: -1\n",
    "# Wait signal: 0\n",
    "\n",
    "def make_label(lista, enable = False):\n",
    "     \n",
    "    # Variable for variation\n",
    "    variation = 0\n",
    "    \n",
    "    for i in range(len(lista)-1):\n",
    "        current_trend = lista[i]['trend'][0]\n",
    "        next_trend = lista[i+1]['trend'][0]\n",
    "        \n",
    "        # Crescent trend: 1\n",
    "        if current_trend == 0 and next_trend == 1:\n",
    "            current_min = min(lista[i]['low'])\n",
    "            next_min = min(lista[i+1]['low'])\n",
    "            \n",
    "            # The inversion point is the min of current or next timeframe\n",
    "            if next_min < current_min:\n",
    "                change = lista[i+1]['low'].idxmin()\n",
    "                lista[i+1].loc[change,'label'] = 1\n",
    "                \n",
    "            else:\n",
    "                change = lista[i]['low'].idxmin()\n",
    "                lista[i].loc[change,'label'] = 1\n",
    "               \n",
    "                \n",
    "        # Decrescent trend: -1\n",
    "        elif current_trend == 1 and next_trend == 0 and enable == True:\n",
    "            current_max = max(lista[i]['high'])\n",
    "            next_max = max(lista[i+1]['high'])\n",
    "            \n",
    "            # The inversion point trend is the max of current or next trend\n",
    "            if next_max > current_max:\n",
    "                change = lista[i+1]['high'].idxmax()\n",
    "                lista[i+1].loc[change,'label'] = -1\n",
    "                \n",
    "            else:\n",
    "                change = lista[i]['high'].idxmax()\n",
    "                lista[i].loc[change,'label'] = -1\n",
    "                \n",
    "                \n",
    "        elif current_trend != next_trend:\n",
    "            lista[i].loc[:,'label'] = np.nan\n",
    "            \n",
    "        \n",
    "\n",
    "        \n",
    "        variation += 100/min(lista[i]['low']*(max(lista[i]['high'])) - (min(lista[i]['low'])))\n",
    "        \n",
    "    \n",
    "    print(\"\\nAverage variation during timeframe: {}\".format(variation/len(lista)))\n",
    "    \n",
    "    return lista\n",
    "\n",
    "\n",
    "def get_indicators(df, timeframe = 180):\n",
    "    \n",
    "    df = StockDataFrame.retype(df)\n",
    "    df['macd'] \n",
    "    df['tema']\n",
    "    df['rsi_12']\n",
    "    \n",
    "    # Max of last timeframe rows\n",
    "    df['max_high']= df['high'].rolling(timeframe).max().shift(1)\n",
    "    \n",
    "    # Min of last timeframe rows\n",
    "    df['min_low']= df['low'].rolling(timeframe).min().shift(1)\n",
    "    \n",
    "    \n",
    "    return df[timeframe:].drop(['rs_12', 'close_-1_s', 'close_-1_d', 'macdh'], axis = 1).dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-shade",
   "metadata": {},
   "source": [
    "# Making the dataframe\n",
    "\n",
    "```df_input``` uses all past function for creating the dataframe that we will use for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "earlier-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_input(csv_name, timeframe = 180, classification = True):\n",
    "    \n",
    "    # Creating df\n",
    "    df = make_df(csv_name)\n",
    "    \n",
    "    # Filling missing data and setting up the timeframe\n",
    "    df = meanfill(df)\n",
    "      \n",
    "    # Making indicators\n",
    "    df = get_indicators(df)\n",
    "     \n",
    "    # Creating samples for evaluate profit \n",
    "    f_sample, s_sample, t_sample, df = all_sample(df)\n",
    "    \n",
    "    if classification:\n",
    "        \n",
    "        # Creating trend and label column\n",
    "        df.loc[:,'trend'] = 0\n",
    "        df.loc[:,'label'] = 0\n",
    "        \n",
    "        # Creating timeframe and fill trend column\n",
    "        df_list = trend(df, timeframe)\n",
    "\n",
    "        # Filling label column\n",
    "        df_list = make_label(df_list, True)\n",
    "        \n",
    "        df = pd.concat(df_list[timeframe:]).dropna().drop(['trend'], axis = 1)\n",
    "      \n",
    "    else:\n",
    "        # Shift min_low and max_high by timeframe, so the i_th row rappresents the max/min of the next \"timeframe\" rows\n",
    "\n",
    "        df['min_low'] = df['min_low'].shift(-timeframe)\n",
    "        df['max_high'] = df['max_high'].shift(-timeframe)\n",
    "\n",
    "    return df.drop(['high', 'low', 'close'], axis = 1).dropna(), f_sample, s_sample, t_sample\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-growth",
   "metadata": {},
   "source": [
    "# Test and Training data\n",
    "\n",
    "The label column is full of zero, if we train the model on the raw data we'll obtain a balanced accuracy of 98% but the model will predict just zero.\n",
    "\n",
    "We used the under sampling method for avoid this fact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "recognized-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling data\n",
    "\n",
    "def under_sampling(X_train, y_train, class_number = 2):\n",
    "    \n",
    "    if class_number == 2:\n",
    "        \n",
    "        sampling_strategy = {0:6000 , 1:1000}\n",
    "        \n",
    "    else:\n",
    "        sampling_strategy = {0:6000 , 1:1000 , -1:1000}\n",
    "          \n",
    "    rus = RandomUnderSampler(sampling_strategy = sampling_strategy)\n",
    "    X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    return X_res, y_res\n",
    "\n",
    "\n",
    "def data_split(df, tag = \"label\", drop = \"\", train_size = None):\n",
    "    \n",
    "    # Drop label column\n",
    "    m_df = df.drop([tag], axis = 1)\n",
    "    \n",
    "    # Drop other column if needed\n",
    "    if drop != \"\":\n",
    "        m_df = m_df.drop([drop], axis = 1)\n",
    "        \n",
    "    \n",
    "    # Splitting into input and output\n",
    "    X = m_df.reset_index(drop=True)\n",
    "    y = df[tag]\n",
    "    \n",
    "    \n",
    "    # Splitting into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, train_size=train_size)\n",
    "\n",
    "    if tag == \"label\":\n",
    "        # undersampling the data\n",
    "        X_train, y_train = under_sampling(X_train, y_train)\n",
    "  \n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-insider",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "We used different model for the prediction:\n",
    "\n",
    "* ```Neural Network```\n",
    "* ```Decision Tree```\n",
    "* ```Random Forest```\n",
    "\n",
    "And evaluted all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "opposite-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10,2,1), random_state=1, max_iter = 10000)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_scaled = scaler.transform(X_train)\n",
    "    \n",
    "    mlp.fit(X_scaled, y_train)\n",
    "    \n",
    "    y_pred = mlp.predict(X_test)\n",
    "    \n",
    "    print(\"Neural Network balanced accuracy \" + str(balanced_accuracy_score(y_test, y_pred)))\n",
    "    return mlp\n",
    "    \n",
    "def decision_tree(X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    # Creiamo il decision Tree\n",
    "    \n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # Addestriamo l'albero\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "\n",
    "    # Eseguiamo delle predizioni sul set di test\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Valutiamo la sua accuratezza\n",
    "    \n",
    "    print(\"Decision Tree Balanced Accuracy: \" + str(balanced_accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    return clf\n",
    "    \n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Creo il modello\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Addestro il modello\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    # Eseguo delle predizioni sul test di test\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    # Valuto l'accuratezza \n",
    "    print(\"Random Forest Balanced Accuracy: \" + str(balanced_accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-welcome",
   "metadata": {},
   "source": [
    "# Evaluating profit\n",
    "\n",
    "I evaluated the models with a simple trading algorithm.\n",
    "But first we will need to take out some random sample from our data, we will evaluate the profit after the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "operating-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_sample(df):\n",
    "    s = np.random.choice(df.index[:-5],1)\n",
    "    sample = df.iloc[df.index.get_loc(s[0]):df.index.get_loc(s[0])+43200]\n",
    "    return sample\n",
    "\n",
    "def all_sample(df):\n",
    "    \n",
    "    \n",
    "    f_sample = single_sample(df)\n",
    "    s_sample = single_sample(df)\n",
    "    t_sample = single_sample(df)\n",
    "\n",
    "    df = pd.concat([df, f_sample, s_sample, t_sample]).drop_duplicates(keep=False)\n",
    "    \n",
    "    return f_sample, s_sample, t_sample, df\n",
    "\n",
    "def evaluate_profit(sample, model, model_name):\n",
    "    \n",
    "    b_price = profit = amount =  transaction_number = transaction_time  = 0\n",
    "    signals = model.predict(sample)\n",
    "    prices = sample['open']\n",
    "  \n",
    "    \n",
    "    # Column with all open value\n",
    "    \n",
    "    for i in range(len(prices)):\n",
    "        \n",
    "        if b_price != 0:\n",
    "            possible_profit = (prices[i] - b_price) * amount\n",
    "        else:\n",
    "            possible_profit = 0\n",
    "        \n",
    "        if signals[i] == 1 and b_price == 0:\n",
    "            transaction_number += 1\n",
    "            b_price = prices[i]\n",
    "            amount = 100/b_price\n",
    "            #print(\"Bought {} coin at {}\".format(amount, b_price))\n",
    "            \n",
    "        if b_price != 0:\n",
    "            \n",
    "            transaction_time += 1\n",
    "            \n",
    "        if b_price != 0 and possible_profit >= 3 :\n",
    "            profit += possible_profit - 0.2\n",
    "            #print(\"Sold {} coin at {} with profit of {}\\n\".format(amount, prices[i], possible_profit))\n",
    "            b_price = 0\n",
    "    \n",
    "    \n",
    "    print(\"TOTAL PROFIT for {}: {}\".format(model_name, profit))\n",
    "    \n",
    "    if(transaction_number != 0):\n",
    "        print(\"Transaction number: {}, average holding for transaction: {}\\n\".format(transaction_number, (transaction_time/transaction_number)/60))\n",
    "    \n",
    "\n",
    "def baseline_profit(sample):\n",
    "    \n",
    "    b_price = profit = amount =  transaction_number = transaction_time  = 0\n",
    "    prices = sample['open']\n",
    "    \n",
    "    # Column with all open value\n",
    "    \n",
    "    for i in range(len(prices)):\n",
    "        \n",
    "        r = random.randint(0,1)\n",
    "        if b_price != 0:\n",
    "            possible_profit = (prices[i] - b_price) * amount\n",
    "        else:\n",
    "            possible_profit = 0\n",
    "        \n",
    "        if r == 1 and b_price == 0:\n",
    "            transaction_number += 1\n",
    "            b_price = prices[i]\n",
    "            amount = 100/b_price\n",
    "            #print(\"Bought {} coin at {}\".format(amount, b_price))\n",
    "            \n",
    "        if b_price != 0:\n",
    "            \n",
    "            transaction_time += 1\n",
    "        \n",
    "        if b_price != 0 and possible_profit >= 3:\n",
    "            profit += possible_profit - 0.2\n",
    "            #print(\"Sold {} coin at {} with profit of {}\\n\".format(amount, prices[i], possible_profit))\n",
    "            b_price = 0\n",
    "          \n",
    "    \n",
    "    print(\"\\n\\nBASELINE PROFIT: {}\".format(profit))\n",
    "    \n",
    "    if(transaction_number != 0):\n",
    "        print(\"Transaction number: {}, average holding for transaction: {}\\n\\n\".format(transaction_number, (transaction_time/transaction_number)/60))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-alliance",
   "metadata": {},
   "source": [
    "# Here start the game\n",
    "\n",
    "That's what we did :\n",
    "\n",
    "* Created the samples and the dataframe\n",
    "* Splitted the data into test and training set\n",
    "* Trained all the models\n",
    "* Evaluated them with balanced accuracy\n",
    "* Evaluted them with our simple trading algo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-services",
   "metadata": {},
   "source": [
    "## BITCOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "periodic-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.12/libexec/lib/python3.9/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average variation during timeframe: 3.06614817558918e-06\n",
      "Random Forest Balanced Accuracy: 0.7629673931176763\n",
      "Decision Tree Balanced Accuracy: 0.7008693737407912\n",
      "Neural Network balanced accuracy 0.35735619678749425\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 11.368588960069296\n",
      "Transaction number: 5, average holding for transaction: 143.98333333333332\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 11.645683505302838\n",
      "Transaction number: 5, average holding for transaction: 143.99666666666664\n",
      "\n",
      "TOTAL PROFIT for Decision Tree: 11.421542629376287\n",
      "Transaction number: 5, average holding for transaction: 142.23333333333332\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 14.237194718689548\n",
      "Transaction number: 6, average holding for transaction: 117.75833333333334\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 49.49376497470577\n",
      "Transaction number: 9, average holding for transaction: 79.9925925925926\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 51.39554410910335\n",
      "Transaction number: 10, average holding for transaction: 71.37666666666668\n",
      "\n",
      "TOTAL PROFIT for Decision Tree: 28.594772542456823\n",
      "Transaction number: 6, average holding for transaction: 79.71388888888889\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 28.892040205768556\n",
      "Transaction number: 5, average holding for transaction: 94.15666666666667\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 3.174701962462571\n",
      "Transaction number: 2, average holding for transaction: 359.93333333333334\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 3.04585602990462\n",
      "Transaction number: 2, average holding for transaction: 360.0\n",
      "\n",
      "TOTAL PROFIT for Decision Tree: 3.280195449349805\n",
      "Transaction number: 2, average holding for transaction: 359.5416666666667\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 3.5266509216943223\n",
      "Transaction number: 2, average holding for transaction: 358.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating df and samples\n",
    "\n",
    "df, f_sample, s_sample, t_sample = df_input(\"./btceur.csv\", 180)\n",
    "\n",
    "# Split data into test and training\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_split(df)\n",
    "\n",
    "# Random forest for BTC\n",
    "BTCrf = random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Decision tree for BTC\n",
    "BTCdt = decision_tree(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Neural Network for BTC\n",
    "BTCnn = neural_network(X_train, y_train, X_test, y_test)\n",
    "\n",
    "#collections.Counter(y_pred)\n",
    "\n",
    "f_sample = f_sample.drop(['high', 'low', 'close'], axis = 1)\n",
    "s_sample = s_sample.drop(['high', 'low', 'close'], axis = 1)\n",
    "t_sample = t_sample.drop(['high', 'low', 'close'], axis = 1)\n",
    "\n",
    "\n",
    "# First sample\n",
    "\n",
    "baseline_profit(f_sample)\n",
    "\n",
    "evaluate_profit(f_sample, BTCnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(f_sample, BTCdt, \"Decision Tree\")\n",
    "\n",
    "evaluate_profit(f_sample, BTCrf, \"Random Forest\")\n",
    "\n",
    "# Second sample\n",
    "\n",
    "baseline_profit(s_sample)\n",
    "\n",
    "evaluate_profit(s_sample, BTCnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(s_sample, BTCdt, \"Decision Tree\")\n",
    "\n",
    "evaluate_profit(s_sample, BTCrf, \"Random Forest\")\n",
    "\n",
    "# Third sample\n",
    "\n",
    "baseline_profit(t_sample)\n",
    "\n",
    "evaluate_profit(t_sample, BTCnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(t_sample, BTCdt, \"Decision Tree\")\n",
    "\n",
    "evaluate_profit(t_sample, BTCrf, \"Random Forest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-universe",
   "metadata": {},
   "source": [
    "## ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "alike-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.0.12/libexec/lib/python3.9/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average variation during timeframe: 0.002654895516053407\n",
      "Random Forest Balanced Accuracy: 0.7349018417762835\n",
      "Decision Tree Balanced Accuracy: 0.6710596103758304\n",
      "Neural Network balanced accuracy 0.3359122176899552\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 57.87198953622203\n",
      "Transaction number: 21, average holding for transaction: 34.26984126984127\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 61.109456065870006\n",
      "Transaction number: 22, average holding for transaction: 32.72727272727273\n",
      "\n",
      "TOTAL PROFIT for Decision Tree: 58.16718157925055\n",
      "Transaction number: 21, average holding for transaction: 33.053174603174604\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 55.0127238561214\n",
      "Transaction number: 20, average holding for transaction: 34.115833333333335\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 20.49596264217177\n",
      "Transaction number: 8, average holding for transaction: 89.97916666666667\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 20.281045973103915\n",
      "Transaction number: 8, average holding for transaction: 90.0\n",
      "\n",
      "TOTAL PROFIT for Decsion Tree: 14.526746724291826\n",
      "Transaction number: 6, average holding for transaction: 116.52777777777779\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 14.410741070028282\n",
      "Transaction number: 6, average holding for transaction: 114.86944444444445\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 35.97104509211839\n",
      "Transaction number: 13, average holding for transaction: 55.37692307692308\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Neural Network: 34.632151630581006\n",
      "Transaction number: 13, average holding for transaction: 55.38461538461538\n",
      "\n",
      "TOTAL PROFIT for Decision Tree: 35.38665508494359\n",
      "Transaction number: 13, average holding for transaction: 54.339743589743584\n",
      "\n",
      "TOTAL PROFIT for Random Forest: 31.75018533857739\n",
      "Transaction number: 12, average holding for transaction: 57.44583333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating df and samples\n",
    "\n",
    "df, f_sample, s_sample, t_sample = df_input(\"./etheur.csv\", 180)\n",
    "\n",
    "# Split data into test and training\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_split(df)\n",
    "\n",
    "# Random forest for BTC\n",
    "ETHrf = random_forest(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Decision tree for BTC\n",
    "ETHdt = decision_tree(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Neural Network for BTC\n",
    "ETHnn = neural_network(X_train, y_train, X_test, y_test)\n",
    "\n",
    "#collections.Counter(y_pred)\n",
    "\n",
    "f_sample = f_sample.drop(['high', 'low', 'close', 'trend', 'label'], axis = 1)\n",
    "s_sample = s_sample.drop(['high', 'low', 'close', 'trend', 'label'], axis = 1)\n",
    "t_sample = t_sample.drop(['high', 'low', 'close', 'trend', 'label'], axis = 1)\n",
    "\n",
    "# First sample\n",
    "\n",
    "baseline_profit(f_sample)\n",
    "\n",
    "evaluate_profit(f_sample, ETHnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(f_sample, ETHdt, \"Decision Tree\")\n",
    "\n",
    "evaluate_profit(f_sample, ETHrf, \"Random Forest\")\n",
    "\n",
    "# Second sampel\n",
    "\n",
    "baseline_profit(s_sample)\n",
    "\n",
    "evaluate_profit(s_sample, ETHnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(s_sample, ETHdt, \"Decsion Tree\")\n",
    "\n",
    "evaluate_profit(s_sample, ETHrf, \"Random Forest\")\n",
    "\n",
    "# Thrid sample\n",
    "\n",
    "baseline_profit(t_sample)\n",
    "\n",
    "evaluate_profit(t_sample, ETHnn, \"Neural Network\")\n",
    "\n",
    "evaluate_profit(t_sample, ETHdt, \"Decision Tree\")\n",
    "\n",
    "evaluate_profit(t_sample, ETHrf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-square",
   "metadata": {},
   "source": [
    "## Crypto local MAX and MIN Prediction\n",
    "\n",
    "In this section we will try to predict the Timeframe Local Minimum and Maximum in order to buy when the value is less then the pred_min and sell when the value is greater then the pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "original-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "def model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(6, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(3, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    \n",
    "    # Compile model\n",
    "    \n",
    "    model.compile(loss=\"mean_absolute_percentage_error\", optimizer='adam')\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, verbose = 0)\n",
    "    \n",
    "    # Evalute the model\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Mean absolute percentage error: {}\".format(mean_absolute_percentage_error(y_test, y_pred)))\n",
    "    \n",
    "    #print(cross_val_score(model, X_test, y_test, scoring = \"neg_mean_absolute_percentage_error\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-compatibility",
   "metadata": {},
   "source": [
    "## Evaluate profit\n",
    "\n",
    "We just changed the if condition of the evaluate_profit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "provincial-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_evaluate_profit(sample, model, model_name):\n",
    "    \n",
    "    b_price = profit = amount =  transaction_number = transaction_time  = 0\n",
    "    signals = model.predict(sample)\n",
    "    prices = sample['open']\n",
    "  \n",
    "    \n",
    "    # Column with all open value\n",
    "    \n",
    "    for i in range(len(prices)):\n",
    "        \n",
    "        if b_price != 0:\n",
    "            possible_profit = (prices[i] - b_price) * amount\n",
    "        else:\n",
    "            possible_profit = 0\n",
    "        \n",
    "        if signals[i] <= prices[i] and b_price == 0:\n",
    "            transaction_number += 1\n",
    "            b_price = prices[i]\n",
    "            amount = 100/b_price\n",
    "            #print(\"Bought {} coin at {}\".format(amount, b_price))\n",
    "            \n",
    "        if b_price != 0:\n",
    "            \n",
    "            transaction_time += 1\n",
    "            \n",
    "        if b_price != 0 and possible_profit >= 3:\n",
    "            profit += possible_profit - 0.2\n",
    "            #print(\"Sold {} coin at {} with profit of {}\\n\".format(amount, prices[i], possible_profit))\n",
    "            b_price = 0\n",
    "    \n",
    "    \n",
    "    print(\"TOTAL PROFIT for {}: {}\".format(model_name, profit))\n",
    "    \n",
    "    if(transaction_number != 0):\n",
    "        print(\"Transaction number: {}, average holding for transaction: {}\\n\".format(transaction_number, (transaction_time/transaction_number)/60))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-uganda",
   "metadata": {},
   "source": [
    "## BTC\n",
    "\n",
    "Making df, train the model, evaluate it with mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "bulgarian-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc, f_sample, s_sample, t_sample = df_input(\"./btceur.csv\", 360, False)\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_split(btc, \"min_low\", drop = \"max_high\", train_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "planned-wireless",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error: 0.013601065151229575\n"
     ]
    }
   ],
   "source": [
    "btc_model = model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "related-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sample = f_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)\n",
    "s_sample = s_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)\n",
    "t_sample = t_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "noble-processor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BASELINE PROFIT: 2.805895100605823\n",
      "Transaction number: 2, average holding for transaction: 359.9916666666667\n",
      "\n",
      "\n",
      "TOTAL PROFIT for First Sample: 2.828533758869696\n",
      "Transaction number: 2, average holding for transaction: 360.0\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 12.525894200233473\n",
      "Transaction number: 5, average holding for transaction: 143.97\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Second Sample: 12.054900579737499\n",
      "Transaction number: 5, average holding for transaction: 144.0\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 3.3126437187524957\n",
      "Transaction number: 2, average holding for transaction: 360.0\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Thirt Sample: 3.3126437187524957\n",
      "Transaction number: 2, average holding for transaction: 360.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate profit comparing it with random trading\n",
    "\n",
    "baseline_profit(f_sample)\n",
    "not_evaluate_profit(f_sample, btc_model, \"First Sample\")\n",
    "\n",
    "baseline_profit(s_sample)\n",
    "not_evaluate_profit(s_sample, btc_model, \"Second Sample\")\n",
    "\n",
    "baseline_profit(t_sample)\n",
    "not_evaluate_profit(t_sample, btc_model, \"Thirt Sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-harvey",
   "metadata": {},
   "source": [
    "## ETH\n",
    "\n",
    "Making df, train the model, evaluate it with mean absolute percentage error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "romance-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth, f_sample, s_sample, t_sample = df_input(\"./etheur.csv\", 360, False)\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_split(btc, tag = \"min_low\", drop = \"max_high\", train_size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "public-equivalent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute percentage error: 0.9988777511394428\n"
     ]
    }
   ],
   "source": [
    "eth_model = model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "northern-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sample = f_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)\n",
    "s_sample = s_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)\n",
    "t_sample = t_sample.drop(['high', 'low', 'close', 'max_high', 'min_low'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "immediate-caution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BASELINE PROFIT: 17.576202813112094\n",
      "Transaction number: 7, average holding for transaction: 102.81666666666666\n",
      "\n",
      "\n",
      "TOTAL PROFIT for First Sample: 17.530878710338587\n",
      "Transaction number: 7, average holding for transaction: 102.85714285714286\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 17.34800250063522\n",
      "Transaction number: 7, average holding for transaction: 102.84523809523809\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Second Sample: 20.296911723494393\n",
      "Transaction number: 8, average holding for transaction: 90.0\n",
      "\n",
      "\n",
      "\n",
      "BASELINE PROFIT: 5.911817787025914\n",
      "Transaction number: 3, average holding for transaction: 239.98333333333332\n",
      "\n",
      "\n",
      "TOTAL PROFIT for Thirt Sample: 8.876754105458577\n",
      "Transaction number: 4, average holding for transaction: 180.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate profit comparing it with random trading\n",
    "\n",
    "baseline_profit(f_sample)\n",
    "not_evaluate_profit(f_sample, eth_model, \"First Sample\")\n",
    "\n",
    "baseline_profit(s_sample)\n",
    "not_evaluate_profit(s_sample, eth_model, \"Second Sample\")\n",
    "\n",
    "baseline_profit(t_sample)\n",
    "not_evaluate_profit(t_sample, eth_model, \"Thirt Sample\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-drinking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
